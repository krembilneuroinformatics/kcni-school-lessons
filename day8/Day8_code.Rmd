---
title: "Day 8 KCNI summer school"
output:
  html_document:
    df_print: paged
    toc: true
  pdf_document: default
---

# Sub-group cluster identification using Similarity Network Fusion (SNF)  

Load required R packages:  
```{r, message=FALSE}
library(SNFtool)
library(mice)
library(rms)
library(here)
library(tidyverse)
```

---
## Steps for analysis:  

0.  update local github repo  
1.  Determine input data space for subtyping  
2.  Normalize inputs  
3.  Calculate distance and adjancency matrices for each data type  
4.  Perform network fusion  
5.  Visualize  
6.  Characterize networks with respect to diagnostic groups and treatment response  


## Step 0 update local repo from github 

Once the kcni-school-lessons git repo has been cloned, you will be able to load the R notebook for day 5 into Rstudio.  

## Step 1 read in datasets to be passed into SNF  
Read in Phenotype data with our primary outcomes of interest
```{r}

pheno_long <- readRDS(here("day8","pheno","longdat.rds"))
head(pheno_long)

pheno_wide <- pheno_long %>%
  pivot_longer(cols = c(age, img1:ses),
               names_to = "measure",
               values_to = "vals") %>%
  pivot_wider(names_from = c("measure","time"),
              values_from = "vals",
              id_cols=c("id","msex","dx",starts_with("geno")))

head(pheno_wide)
```

*** 
#### Read in our high-dimensional data:  
1. gene expression from prefrontal cortex  
2. EEG parameters (electrode peak frequencies + cognitive model parameters)  
3. epigenomic environmental exposure (methylation cpgs)  

```{r}
expr <- readRDS(here("day8", "snfdata", "expr.rds"))
expr[1:5,1:5]

eeg <- readRDS(here("day8", "snfdata", "eeg.rds"))
eeg[1:5,1:5]

meth <- readRDS(here("day8","snfdata","methyl.rds"))
meth[1:5,1:5]
```

We will generate patient similarity newtorks for each of these data types and then fuse the networks. First we should know if there is missingness in our data. To demonstrate how this can be handled, we will introduce some random missingness into our wide dataframe:  

```{r}
# here we make a copy of the pheno_wide dataset
pw_miss <- pheno_wide

# we're not introducing missingness to the ID or msex columns
n <- nrow(pw_miss)
set.seed(1234)
pw_miss[,-c(1:3)] <- apply(pw_miss[,-c(1:3)], 2, function(x) {x[sample( c(1:n), floor(n/20))] <- NA; x} )
```

A method for assessing missiness in a large dataset:  
```{r}
naout <- apply(pw_miss,2,function(col) {is.na(col)})
table(naout)

apply(naout,2,sum)
```

For smaller datasets, we can use visualizations:  
```{r}
# just the top 50 observations, so not all variable have missing values in this visualization
md.pattern(pw_miss[1:50,],rotate.names = T)

# a red square indicates some missing obserations
# left y-axis indicates the number of missing obervations for each data type in each row
# right y-axis indicates TOTAL number of missing observations in each row
# x-axis indicates total missing observations PER VARIABLE
```

We have a few options for dealing with missing values:  
1. We can remove variables and/or subjects  
2. We can perform any number of imputation algorithms to estimate the missing values  

We should understand the type of missingness we have:  
- Missing completely at random (MCAR)  e.g. technical sample loss, dy design  
- Missing at random (MAR)  e.g. missing but may be related to other observations  
- Missing not at random (MNAR)  e.g. missing for unobserved or unknown reasons  

In our case, missing data are MAR. We can perform imputation by predictive mean matching (PMM):  
```{r}
imp <- mice(pw_miss,method="pmm",maxit=1,seed=1,print=F)
newdat <- complete(imp)
paste0("Missing observations remaining = ",sum(is.na(newdat)))
```

Hey wait, I thought we were imputing missing values!? Not-so-fun fact - the mice algorithm will not impute variables that are perfectly co-linear with at least one other variable. In our case, the age variables (age.0 and age.1) are perfectly co-linear, because the time between visits is fixed (6 months).  
```{r}
plot(pheno_wide$age_0,pheno_wide$age_1)

# let's simplify things and create one age variable, representing age at baseline (age.0)
pheno_wide$age <- pheno_wide$age_0
pheno_wide$age_1 <- NULL
```

So in reality, we haven't lost any information and all remaining variables have been imputed successfully.

***
## The SNF workflow

### 1. Select hyperparameters
```{r}
# method recommended for nearest neighbors: K = N/C  [where N=sample size, C=# of theoretical clusters]
K = 25		# number of neighbors, usually (10~30)
alpha = 0.5  	# hyperparameter, usually (0.3~0.8)
T = 10 	# Number of Iterations, usually (10~20)
```

### 2. Normalize the input data  
```{r}
# first we must make sure we match the subject names (in columns) across each of our input matrices.
meth <- meth[,colnames(expr)]
eeg <- eeg[,colnames(expr)]

# it helps the workflow to create a list object with each of the input data frames - we transpose here so that subjects are in rows, rather than columns.
dataL <- list(expr=t(expr),eeg=t(eeg),meth=t(meth))

dataL = lapply(dataL, standardNormalization)

expr[1:5,1:5]
dataL$expr[1:5,1:5]
```

### 3. Calculate subject-wise adjacency matrices (networks)
```{r}
distL = lapply(dataL, function(x) (dist2(x, x))^(1/2)) 

lapply(distL,dim)

affinityL = lapply(distL, function(x) affinityMatrix(x, K, alpha))
```

### 4. Perform network fusion
```{r}
# Construct the fused network
networkW = SNF(affinityL, K, T)
networkW[1:5,1:5]
```

### 5. Cluster the fused network  
```{r}
# use heuristics to estimate optimal number of clusters
estimateNumberOfClustersGivenGraph(networkW, NUMC=2:10)

# Perform clustering on the fused network.
clustering4 = spectralClustering(networkW,4) # number of clusters?
clustering3 = spectralClustering(networkW,3)

# Let's visualize this object as a martix and a network
displayClusters(networkW,clustering3)
displayClusters(networkW,clustering4)

# Plot parallel coordinates (alluvial) for possible cluster choices
plotAlluvial(networkW,clust.range = 3:4)

# save our cluster definitions into a dataframe with subject ids
clusters <- data.frame(snfid=colnames(networkW),
                       clust3=as.factor(clustering3),
                       clust4=as.factor(clustering4))

# use an id key to match SNF subjects (snfid) with phenotype dataset subjects (phenoid)
idkey <- readRDS("idkey.rds")
clusters$phenoid <- idkey$phenoid[match(clusters$snfid,idkey$snfid)]

# examine the clusters dataframe
head(clusters)
```



### 6. Test for associations of group membership with witheld variables

```{r}
# what is the cluster overlap with clinical diagnoses?
pheno <- merge(pheno_wide,clusters,by.x="id",by.y="phenoid")

dxtable <- table(pheno$dx,pheno$clust4)
dxtable 

chisq.test(dxtable)

dx_plot <- as.data.frame(dxtable)
names(dx_plot) <- c("dx","clust","count")

ggplot(data=dx_plot, aes(x=as.factor(clust), y=count, fill=dx)) +
  geom_bar(stat="identity",position="fill", width=1) +
  labs(y="proportion of subjects","SNF cluster",fill="Clinical diagnosis")+
  theme_minimal()
```

```{r}
# let's test a primary outcome: change in depression score between time 0 and 1, i.e. before/after treatment (cog3diff)
pheno$cog3diff <- pheno$cog3_1 - pheno$cog3_0

mod1 <- lm(data=pheno, cog3diff ~ as.factor(clust4) + msex + age + ses_0)
anova(mod1)
summary(mod1)

ggplot(data=pheno, aes(x=as.factor(clust4), y=cog3diff,col=as.factor(clust4))) +
  geom_boxplot() +
  geom_jitter(width=0.1)+
  geom_hline(yintercept=0,lty=2)+
  labs(y="change in symptoms",x="SNF Cluster",col="SNF cluster")+
  theme_minimal()

# how does this compare with predictive power for classical diagnoses?
mod2 <- lm(data=pheno, cog3diff ~ as.factor(dx) + msex + age + ses_0)
anova(mod2)
summary(mod2)

ggplot(data=pheno, aes(x=as.factor(dx), y=cog3diff,col=as.factor(dx))) +
  geom_boxplot() +
  geom_jitter(width=0.1)+
  geom_hline(yintercept=0,lty=2)+
  labs(y="change in symptoms",x="Clinical diagnosis",col="Dx")+
  theme_minimal()

# let's put some clinically-relevant measures on this.
# for example, let's impose a threshold to our response cog3diff, such that only subjects who experienced a decrease in symptoms are classified as respondants (cog3diff < 0)

pheno$resp <- as.factor(ifelse(pheno$cog3diff < 0,"responder","nonresponder"))

mod3 <- lrm(data=pheno, resp ~ clust4 + msex + age + ses_0)
mod4 <- lrm(data=pheno, resp ~ dx + msex + age + ses_0)

results <- data.frame(snf=mod3$stats,dx=mod4$stats)
results

# The C statistic (concordance) in discriminative analyses (like here in logistic regression) is equivalent to the area uner the receiving operating characteristics curve (AUC). 
# i.e. How often will the model predict a higher probability of response in someone who truly is a responder vs. someone who is not.
# For SNF clusters C=0.77, for traditional diagnosis C=0.68
```


### 7. Identify the key features from each network that influence group membership

```{r}
rankedfeatures <- rankFeaturesByNMI(dataL, networkW)

# the algorithm does not label the lists within rankedfeatures, so we will, for clarity
names(rankedfeatures) <- c("NMI","rank")
names(rankedfeatures$NMI)<- names(dataL)
names(rankedfeatures$rank) <- names(dataL)

str(rankedfeatures)

# identify which feature set has the features with highest NMI
lapply(rankedfeatures,function(x) { lapply(x,function(y) { range(y) })})

# the meth dataset has the feature with the highest NMI, but let's see what the top features are from each data type...
colnames(dataL$expr)[rankedfeatures$rank$expr][1]
colnames(dataL$eeg)[rankedfeatures$rank$eeg][1]
colnames(dataL$meth)[rankedfeatures$rank$meth][1]

# let's look at the top feature and verify that it is important to our fused network structure
# Since we matched our external phenotype data to our clustering results using an ID key, we need to make sure the original data are labelled correctly for merging
meth2 <- as.data.frame(dataL$meth)
meth2$id <- row.names(meth2)
pheno2 <- merge(meth2,pheno,by.x="id",by.y="snfid")

# test for statistical association and plot
anova(lm(data=pheno2, cg10444350 ~ clust4))
ggplot(data=pheno2, aes(y=cg10444350,x=clust4,col=clust4))+
  geom_boxplot()+
  geom_jitter()+
  theme_minimal()
```

It's good practice to add a call to `sessionInfo`. This will add a log of what R packages (and what versions of those packages) you used to generate the results.

```{r}
sessionInfo()
```


### 8. If time, nice network plots in R

Load packages
```{r}
library(network,quietly = T,warn.conflicts = F)
library(sna,quietly = T,warn.conflicts = F)
library(ggnetwork,quietly = T,warn.conflicts = F)
library(ggsci,quietly = T,warn.conflicts = F)
```

Reshape the fused network into a long-format table, define edges and nodes, subset to "linked" nodes

```{r}
netdf <- lower.tri.remove(networkW) # matrix is symmetrical, we designate half of it at NA with lower.tri.remove

netdf <- as.data.frame(netdf) %>%
  mutate(sub1 = row.names(.)) %>%
  pivot_longer(!sub1,
               names_to = "sub2",
               values_to = "value") %>%
  mutate(sub1 = str_pad(sub1,4, "left", "0"),
         sub2 = str_pad(sub2,4, "left", "0")) 

netdf_sub <- netdf %>%
  drop_na(value) %>%
  filter(value < 0.5 & sub1 != sub2) %>%
  filter(value > quantile(value,0.95))
```


Format the edge list into a ggnetwork object - a flat data frame - for plotting with ggplot
```{r}
edges <- netdf_sub[,c("sub1","sub2")]

edges_forplot <- network(edges,directed=F)
x <- data.frame(vertices=network.vertex.names(edges_forplot))
set.edge.attribute(edges_forplot,"similarity", netdf_sub$value)

n <- ggnetwork(edges_forplot)
n$cluster3 <- pheno2$clust3[match(n$vertex.names,pheno2$id)]
n$cluster4 <- pheno2$clust4[match(n$vertex.names,pheno2$id)]

ggplot(n, aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_edges(aes(size=similarity),curvature=0,show.legend = F) +
  geom_nodes(aes(fill=cluster4,shape=vertex.dx),alpha=0.9,size=7,pch=21,col="black") +  # try substituting cluster3 with cluster4!
  scale_size_continuous(range=c(0.1,3))+
  scale_fill_jco()+
  labs(title="Fused similarity network (n=106)")+
  theme_blank()
```


